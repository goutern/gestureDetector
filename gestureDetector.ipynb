{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CS585_Lab3\n",
    "CS585 Image and Video Computing\n",
    "Lab 3\n",
    "--------------\n",
    "This program introduces the following concepts:\n",
    "\ta) Reading a stream of images from a webcamera, and displaying the video\n",
    "\tb) Skin color detection\n",
    "\tc) Background differencing\n",
    "\td) Visualizing motion history\n",
    "--------------\n",
    "'''\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "max_thresh = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_skin_detect(src) :\n",
    "    '''\n",
    "    Function that detects whether a pixel belongs to the skin based on RGB values\n",
    "    Args: \n",
    "        src The source color image\n",
    "    Returns: \n",
    "        dst The destination grayscale image where skin pixels are colored white and the rest are colored black\n",
    "    Surveys of skin color modeling and detection techniques:\n",
    "    Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "    Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "    '''\n",
    "    dst = np.zeros(np.shape(src)[:-1], dtype=np.uint8)\n",
    "    mask = np.logical_and.reduce((src[:,:,2] > 94 ,src[:,:,1] > 40, src[:,:,0] > 20 ))\n",
    "    dst[mask] = 255\n",
    "    return dst\n",
    "\n",
    "def my_frame_differencing(prev, curr):\n",
    "    '''\n",
    "    Function that does frame differencing between the current frame and the previous frame\n",
    "    Args:\n",
    "        src The current color image\n",
    "        prev The previous color image\n",
    "    Returns:\n",
    "        dst The destination grayscale image where pixels are colored white if the corresponding pixel intensities in the current\n",
    "    and previous image are not the same\n",
    "    '''\n",
    "    dst = cv2.absdiff(prev, curr)\n",
    "    gs = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    dst = (gs > 50).astype(np.uint8) * 255\n",
    "    return dst\n",
    "\n",
    "def my_motion_energy(mh):\n",
    "    '''\n",
    "    Function that accumulates the frame differences for a certain number of pairs of frames\n",
    "    Args:\n",
    "        mh Vector of frame difference images\n",
    "    Returns:\n",
    "        dst The destination grayscale image to store the accumulation of the frame difference images\n",
    "    '''\n",
    "    dst = np.zeros(np.shape(mh[0][:,:]), dtype=np.uint8)\n",
    "\n",
    "    mask = np.logical_or.reduce((mh[0][:,:] == 255, mh[1][:,:] == 255, mh[2][:,:] == 255))\n",
    "\n",
    "    dst[mask] = 255\n",
    "    return dst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "def hand_capture():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    gestures = []\n",
    "    # if not successful, exit program\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open the video cam\")\n",
    "        sys.exit()\n",
    "\n",
    "    # create a window called \"MyVideo0\"\n",
    "    cv2.namedWindow(\"Webcam\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # read a new frame from video\n",
    "    ret, frame0 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "    images = 0\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Cannot read a frame from video stream\")\n",
    "            break\n",
    "\n",
    "\n",
    "        cv2.putText(frame,\"Please take a picture with no hands in view, press space to capture when ready.\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(30) == 32:\n",
    "            background = cv2.cvtColor(my_skin_detect(frame),cv2.COLOR_GRAY2BGR)\n",
    "            break\n",
    "\n",
    "    while(images < 3):\n",
    "        # read a new frame from video\n",
    "        ret, frame = cap.read()\n",
    "        # if not successful, break loop\n",
    "        if not ret:\n",
    "            print(\"Cannot read a frame from video stream\")\n",
    "            break\n",
    "\n",
    "        frame = clean_gesture(frame, background)\n",
    "        if images == 0:\n",
    "                cv2.putText(frame,\"Please make a hand gesture, press space to capture when ready.\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        if images == 1:\n",
    "                cv2.putText(frame,\"Please make a second hand gesture, press space to capture when ready.\",(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        if images == 2:\n",
    "                cv2.putText(frame,\"Please make the last gesture, press space to capture when ready.\",(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        if cv2.waitKey(30) == 32:\n",
    "            images += 1\n",
    "            if images == 1:\n",
    "                gestures.append(frame)\n",
    "            if images == 2:\n",
    "                gestures.append(frame)\n",
    "            if images == 3:\n",
    "                gestures.append(frame)\n",
    "                break\n",
    "\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return gestures, background\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "def clean_gesture(frame, background):\n",
    "    image = my_skin_detect(frame)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "    image = my_frame_differencing(background, image)\n",
    "    # cv2.namedWindow('Skin')\n",
    "    # cv2.imshow('Skin', image)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # cv2.namedWindow('Grey')\n",
    "    # cv2.imshow('Grey', image)\n",
    "    _, thres_output = cv2.threshold(image, 125 , max_thresh, 0)\n",
    "    contours, hierarchy = cv2.findContours(thres_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_output = cv2.cvtColor(np.zeros(thres_output.shape,dtype='uint8'),cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    max_id = max(enumerate(contours), key=lambda x : cv2.contourArea(x[1]))[0]\n",
    "\n",
    "    cv2.drawContours(contour_output, contours, max_id, (255, 0,0), cv2.FILLED, 8)\n",
    "    cv2.drawContours(contour_output, contours, max_id, (0, 0,255), 2, 8)\n",
    "\n",
    "    # cv2.namedWindow('Contours')\n",
    "    # cv2.imshow('Contours', contour_output)\n",
    "    return contour_output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esc key is pressed by user\n"
     ]
    }
   ],
   "source": [
    "# gestures = clean_gesture(gest ures)\n",
    "# ----------------\n",
    "# a) Reading a stream of images from a webcamera, and displaying the video\n",
    "# ----------------\n",
    "# For more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "# open the video camera no. 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not successful, exit program\n",
    "if not cap.isOpened(): \n",
    "    print(\"Cannot open the video cam\")\n",
    "    sys.exit()\n",
    "\n",
    "# create a window called \"MyVideo0\"\n",
    "# cv2.namedWindow(\"Webcam\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# read a new frame from video\n",
    "ret, frame0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Cannot read a frame from video stream\")\n",
    "\n",
    "gestures, background = hand_capture( )\n",
    "# show the frame in \"Webcam\" window\n",
    "# cv2.imshow(\"Webcam\", frame0)\n",
    "\n",
    "# create windows\n",
    "# cv2.namedWindow(\"MyVideo\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow(\"FrameDiff\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow(\"MotionEnergy\", cv2.WINDOW_AUTOSIZE)\n",
    "#\n",
    "# my_motion_history = []\n",
    "# fMH1 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "# fMH2 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "# fMH3 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "# my_motion_history.append(fMH1)\n",
    "# my_motion_history.append(fMH2)\n",
    "# my_motion_history.append(fMH3)\n",
    "\n",
    "while(1):\n",
    "    # read a new frame from video\n",
    "    ret, frame = cap.read()\n",
    "    # if not successful, break loop\n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        break\n",
    "    clean = clean_gesture(frame, background)\n",
    "    if cv2.matchTemplate(clean, gestures[0], cv2.TM_CCOEFF_NORMED) >= 0.8:\n",
    "        cv2.putText(frame,\"Gesture 1 Detected\",(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    elif cv2.matchTemplate(clean, gestures[1], cv2.TM_CCOEFF_NORMED) >= 0.8:\n",
    "        cv2.putText(frame,\"Gesture 2 Detected\",(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    elif cv2.matchTemplate(clean, gestures[2], cv2.TM_CCOEFF_NORMED) >= 0.8:\n",
    "        cv2.putText(frame,\"Gesture 3 Detected\",(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame,\"No Gesture Detected\",(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    # wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"esc key is pressed by user\")\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}